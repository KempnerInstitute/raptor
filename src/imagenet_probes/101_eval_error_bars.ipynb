{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init_imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "# Add parent directory to path to import utils etc\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"\")))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"\"))))\n",
    "\n",
    "from utils import find_raptor_checkpoint\n",
    "from dataloader import imagenet_transform\n",
    "from dino_wrapper import DinoModelWrapper\n",
    "from raptor_wrapper import RaptorWrapper\n",
    "from overcomplete.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import IMAGENET_VAL_DIR\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(\"src\")))\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Configurations from run_all.sh\n",
    "experiments = [\n",
    "    {\"variant\": \"dino_s\", \"seed\": 4000, \"model_seed\": None},\n",
    "    {\"variant\": \"dino_b\", \"seed\": 4001, \"model_seed\": None},\n",
    "    {\"variant\": \"raptor2\", \"model_seed\": 1001, \"seed\": 4002},\n",
    "    {\"variant\": \"raptor2\", \"model_seed\": 1002, \"seed\": 4003},\n",
    "    {\"variant\": \"raptor2\", \"model_seed\": 1003, \"seed\": 4004},\n",
    "    {\"variant\": \"raptor3\", \"model_seed\": 1101, \"seed\": 4005},\n",
    "    {\"variant\": \"raptor3\", \"model_seed\": 1102, \"seed\": 4006},\n",
    "    {\"variant\": \"raptor3\", \"model_seed\": 1103, \"seed\": 4007},\n",
    "    {\"variant\": \"raptor4\", \"model_seed\": 1201, \"seed\": 4008},\n",
    "    {\"variant\": \"raptor4\", \"model_seed\": 1202, \"seed\": 4009},\n",
    "    {\"variant\": \"raptor4\", \"model_seed\": 1203, \"seed\": 4010}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = datasets.ImageFolder(root=IMAGENET_VAL_DIR, transform=imagenet_transform())\n",
    "val_loader = DataLoader(\n",
    "    valset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=8, pin_memory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_loading_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_classifier(variant, model_seed, probe_seed, device):\n",
    "    # Generate classifier filename based on train_probe.py logic\n",
    "    if variant.startswith(\"raptor\"):\n",
    "        classifier_filename = f\"{variant}_classifier_modelseed_{model_seed}_probeseed_{probe_seed}.pt\"\n",
    "    else:\n",
    "        classifier_filename = f\"{variant}_classifier_probeseed_{probe_seed}.pt\"\n",
    "    \n",
    "    classifier_path = os.path.abspath(classifier_filename)\n",
    "    if not os.path.exists(classifier_path):\n",
    "        print(f\"Warning: Classifier not found at {classifier_path}\")\n",
    "        return None, None\n",
    "\n",
    "    if variant.startswith(\"raptor\"):\n",
    "        try:\n",
    "            raptor_model_path = find_raptor_checkpoint(variant, model_seed, BASE_DIR)\n",
    "            print(f\"Loading Raptor backbone from: {raptor_model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error locating Raptor checkpoint: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "        try:\n",
    "            model_state = torch.load(raptor_model_path, map_location=device)\n",
    "            dino = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vitb14_reg\").to(device)\n",
    "            model = RaptorWrapper(model_state, dino) # classifier init handled separately\n",
    "            \n",
    "            # Load classifier weights\n",
    "            model.classifier.load_state_dict(torch.load(classifier_path, map_location=device))\n",
    "            \n",
    "            model.dino.eval()\n",
    "            model.raptor.eval()\n",
    "            model.classifier.eval()\n",
    "            model = model.to(device).float()\n",
    "            \n",
    "            # Return both model and dino reference for consistency in eval step\n",
    "            return model, dino\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Raptor model: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    elif variant.startswith(\"dino\"):\n",
    "        dino_name = \"dinov2_vits14_reg\" if variant == \"dino_s\" else \"dinov2_vitb14_reg\"\n",
    "        print(f\"Loading Dino model: {dino_name}\")\n",
    "        model = DinoModelWrapper(dino_model=dino_name, device=device).to(device)\n",
    "        \n",
    "        # Load classifier weights\n",
    "        model.classifier.load_state_dict(torch.load(classifier_path, map_location=device))\n",
    "        model.dino.eval()\n",
    "        model.classifier.eval()\n",
    "        model = model.to(device).float()\n",
    "        \n",
    "        # For Dino wrapper, dino itself is inside execution flow usually, but our step fn might differ\n",
    "        # Lets check validation_step logic\n",
    "        return model, None\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(model, dino_ref, dataloader, variant):\n",
    "    model.eval()\n",
    "    accs = 0.0\n",
    "    r2s = 0.0\n",
    "    num_samples = 0\n",
    "    \n",
    "    is_raptor = variant.startswith(\"raptor\")\n",
    "    \n",
    "    if is_raptor and dino_ref is not None:\n",
    "        dino_ref.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            batch_size = x.size(0)\n",
    "            num_samples += batch_size\n",
    "\n",
    "            if is_raptor:\n",
    "                # Raptor forward: logits, a_pred\n",
    "                logits, a_pred = model(x, layer_start=0, layer_end=12)\n",
    "            else:\n",
    "                # Dino variant\n",
    "                logits, _ = model(x, layer_start=0, layer_end=12)\n",
    "            \n",
    "            # Compute Accuracy\n",
    "            pred_label = logits.argmax(dim=1)\n",
    "            #accs += (pred_label == y).float().sum().item()\n",
    "            accs += (pred_label == y).sum().item()\n",
    "            \n",
    "            # Compute R2 for Raptor\n",
    "            if is_raptor:\n",
    "                 # dino_ref is a DinoModelWrapper instance\n",
    "                 _, a_dino = dino_ref(x, layer_start=0, layer_end=12)\n",
    "                 \n",
    "                 # Calculate R2\n",
    "                 if a_pred is not None and a_dino is not None:\n",
    "                     if a_pred.shape == a_dino.shape:\n",
    "                         # Using metric from 101_eval\n",
    "                         current_r2 = r2_score(a_pred.reshape(-1, a_pred.size(3)), a_dino.reshape(-1, a_dino.size(3)))\n",
    "                         r2s += current_r2 * batch_size\n",
    "                                \n",
    "    avg_acc = accs / num_samples\n",
    "    if is_raptor:\n",
    "        avg_r2 = r2s / num_samples\n",
    "        avg_r2 = avg_r2.item()\n",
    "    else:\n",
    "        avg_r2 = 0.0 # R2 not applicable for pure Dino classification probe evaluation context usually\n",
    "        \n",
    "    return avg_acc, avg_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper_dino_ref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a shared DinoModelWrapper for computing ground-truth R2 targets\n",
    "dino_ref = DinoModelWrapper(device=DEVICE).to(DEVICE).float()\n",
    "dino_ref.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for exp in experiments:\n",
    "    print(f\"Processing {exp}\")\n",
    "    model, _ = load_model_and_classifier(exp[\"variant\"], exp[\"model_seed\"], exp[\"seed\"], DEVICE)\n",
    "    \n",
    "    if model is None:\n",
    "        print(f\"Skipping {exp} due to load failure\")\n",
    "        continue\n",
    "        \n",
    "    # Run evaluation\n",
    "    acc, r2 = validation_step(model, dino_ref, val_loader, exp[\"variant\"])\n",
    "    print(f\"Result: Acc={acc:.4f}, R2={r2:.4f}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"variant\": exp[\"variant\"],\n",
    "        \"seed\": exp[\"seed\"],\n",
    "        \"model_seed\": exp[\"model_seed\"],\n",
    "        \"acc\": acc,\n",
    "        \"r2\": r2\n",
    "    })\n",
    "    \n",
    "    # Free memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_json(\"eval_results.json\", orient=\"records\")\n",
    "print(\"Results saved to eval_results.json\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agg_and_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results\n",
    "agg = results_df.groupby(\"variant\").agg({\n",
    "    \"acc\": [\"mean\", \"std\"],\n",
    "    \"r2\": [\"mean\", \"std\"]\n",
    "})\n",
    "\n",
    "# Extract values for plotting\n",
    "# Variants: raptor2, raptor3, raptor4, dino_s, dino_b\n",
    "def get_stats(variant_name):\n",
    "    if variant_name in agg.index:\n",
    "        mean = agg.loc[variant_name, (\"acc\", \"mean\")]\n",
    "        std = agg.loc[variant_name, (\"acc\", \"std\")]\n",
    "        r2_mean = agg.loc[variant_name, (\"r2\", \"mean\")]\n",
    "        r2_std = agg.loc[variant_name, (\"r2\", \"std\")]\n",
    "        return mean, std, r2_mean, r2_std\n",
    "    return 0, 0, 0, 0\n",
    "\n",
    "raptor2_acc, raptor2_err, raptor2_r2, raptor2_r2_err = get_stats(\"raptor2\")\n",
    "raptor3_acc, raptor3_err, raptor3_r2, raptor3_r2_err = get_stats(\"raptor3\")\n",
    "raptor4_acc, raptor4_err, raptor4_r2, raptor4_r2_err = get_stats(\"raptor4\")\n",
    "\n",
    "dino_s_acc, _, _, _ = get_stats(\"dino_s\")\n",
    "dino_b_acc, _, _, _ = get_stats(\"dino_b\")\n",
    "\n",
    "def plot_bar_acc_r2_with_error(accs, acc_errs, r2s, r2_errs, dino_s_acc, dino_b_acc, fontsize=16):\n",
    "    sns.set_theme()\n",
    "    fig, ax1 = plt.subplots(figsize=(8,8))\n",
    "\n",
    "    # Data prep\n",
    "    # Normalized to Dino Base Accumacy\n",
    "    acc_norm = [(a / dino_b_acc) * 100.0 for a in accs]\n",
    "    # Error bars also need scaling\n",
    "    acc_err_norm = [(e / dino_b_acc) * 100.0 for e in acc_errs]\n",
    "    \n",
    "    dino_s_norm = (dino_s_acc / dino_b_acc) * 100.0\n",
    "    \n",
    "    xs = np.array([2, 3, 4])\n",
    "    width = 0.35\n",
    "    x_idx = np.arange(len(xs))\n",
    "\n",
    "    acc_color = sns.color_palette(\"muted\")[0]   # soft blue\n",
    "    r2_color = sns.color_palette(\"muted\")[1]    # soft orange\n",
    "\n",
    "    # Dino Baseline\n",
    "    ax1.axhline(dino_s_norm, label=\"DINOv2 ViT-S Acc (%)\", linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "    # ---- Left axis: Accuracy ----\n",
    "    bars_acc = ax1.bar(x_idx - width/2, acc_norm, width, yerr=acc_err_norm,\n",
    "                       label=\"RAPTOR Acc (%)\", color=acc_color, capsize=5)\n",
    "    \n",
    "    ax1.set_ylabel(\"Accuracy (% of ViT-B)\", color=acc_color, fontsize=fontsize)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=acc_color)\n",
    "    # Adjust ylim to visually fit\n",
    "    ax1.set_ylim(90, 100)\n",
    "    \n",
    "    # ---- Right axis: R2 ----\n",
    "    ax2 = ax1.twinx()\n",
    "    bars_r2 = ax2.bar(x_idx + width/2, r2s, width, yerr=r2_errs,\n",
    "                      label=\"RAPTOR R²\", color=r2_color, capsize=5)\n",
    "    ax2.set_ylabel(\"R²\", color=r2_color, fontsize=fontsize)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=r2_color, labelsize=fontsize)\n",
    "    ax2.set_ylim(0.5, 1.0)\n",
    "\n",
    "    # ---- Labels ----\n",
    "    # Acc labels\n",
    "    for bar in bars_acc:\n",
    "        h = bar.get_height()\n",
    "        # For text, we can show raw acc or scaled? Lets show scaled value\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, h + 0.2, f\"{h:.1f}\",\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=fontsize-4, color=acc_color)\n",
    "    \n",
    "    # R2 labels\n",
    "    for bar in bars_r2:\n",
    "        h = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, h + 0.02, f\"{h:.2f}\",\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=fontsize-4, color=r2_color)\n",
    "\n",
    "    # ---- X axis ----\n",
    "    ax1.set_xticks(list(x_idx))\n",
    "    ax1.set_xticklabels([\"2\", \"3\", \"4\"], fontsize=fontsize)\n",
    "    ax1.set_xlabel(\"Number of Recurrent Blocks\", fontsize=fontsize)\n",
    "\n",
    "    # ---- Legends ----\n",
    "    h1, l1 = ax1.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(h1 + h2, l1 + l2, fontsize=12, loc=\"upper left\")\n",
    "\n",
    "    ax1.tick_params(axis=\"both\", labelsize=fontsize)\n",
    "    ax2.tick_params(axis=\"both\", labelsize=fontsize)\n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"raptor_vs_dino_bar_scaled_error_bars.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "acc_list = [raptor2_acc, raptor3_acc, raptor4_acc]\n",
    "acc_err_list = [raptor2_err, raptor3_err, raptor4_err]\n",
    "r2_list = [raptor2_r2, raptor3_r2, raptor4_r2]\n",
    "r2_err_list = [raptor2_r2_err, raptor3_r2_err, raptor4_r2_err]\n",
    "\n",
    "plot_bar_acc_r2_with_error(acc_list, acc_err_list, r2_list, r2_err_list, dino_s_acc, dino_b_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf4ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slot_attention6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
